{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOPIC Identification of Mathematical word problems\n",
    "- In a smaller dataset , I have manually categorized the word problems and used Keras deep learning to classifiy the questions \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the updated AQuA Dataset with classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#qb =  pd.read_json('AQuA-master/dev.json',lines=True)\n",
    "qbc =  pd.read_csv('dev-class5.csv',index_col=False)\n",
    "#qbc.reset_index()\n",
    "#qbc = qbc.join(qbc['QOR'].apply(json.loads).apply(pd.Series))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>correct</th>\n",
       "      <th>options</th>\n",
       "      <th>question</th>\n",
       "      <th>rationale</th>\n",
       "      <th>qn</th>\n",
       "      <th>clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>['A)32400', 'B)6000', 'C)600', 'D)60000', 'E)10']</td>\n",
       "      <td>Three birds are flying at a fast rate of 900 k...</td>\n",
       "      <td>To calculate the equivalent of miles in a kilo...</td>\n",
       "      <td>three birds are flying at a fast rate of  kilo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>['A)100 m', 'B)150 m', 'C)200 m', 'D)250 m', '...</td>\n",
       "      <td>A ship is leaving a port. It takes 240 seconds...</td>\n",
       "      <td>Let the length of the ship be x metres and its...</td>\n",
       "      <td>a ship is leaving a port. it takes  seconds to...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "      <td>['A)6', 'B)18', 'C)24', 'D)36', 'E)48']</td>\n",
       "      <td>A rectangular piece of cloth 2 feet wide was c...</td>\n",
       "      <td>The question says, length of shorter piece is ...</td>\n",
       "      <td>a rectangular piece of cloth  feet wide was cu...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "      <td>['A)(1,1)', 'B)(0,3)', 'C)(2,0)', 'D)(3,6)', '...</td>\n",
       "      <td>In the xy-coordinate plane, which of the follo...</td>\n",
       "      <td>For a point to satisfy the given equation for ...</td>\n",
       "      <td>in the xy-coordinate plane, which of the follo...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>C</td>\n",
       "      <td>['A)7', 'B)9', 'C)13', 'D)27', 'E)45']</td>\n",
       "      <td>A travel company wants to charter a plane to t...</td>\n",
       "      <td>Additional passengers (i.e., an integer, let's...</td>\n",
       "      <td>a travel company wants to charter a plane to t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 correct                                            options  \\\n",
       "0           0       A  ['A)32400', 'B)6000', 'C)600', 'D)60000', 'E)10']   \n",
       "1           1       D  ['A)100 m', 'B)150 m', 'C)200 m', 'D)250 m', '...   \n",
       "2           2       C            ['A)6', 'B)18', 'C)24', 'D)36', 'E)48']   \n",
       "3           3       B  ['A)(1,1)', 'B)(0,3)', 'C)(2,0)', 'D)(3,6)', '...   \n",
       "4           4       C             ['A)7', 'B)9', 'C)13', 'D)27', 'E)45']   \n",
       "\n",
       "                                            question  \\\n",
       "0  Three birds are flying at a fast rate of 900 k...   \n",
       "1  A ship is leaving a port. It takes 240 seconds...   \n",
       "2  A rectangular piece of cloth 2 feet wide was c...   \n",
       "3  In the xy-coordinate plane, which of the follo...   \n",
       "4  A travel company wants to charter a plane to t...   \n",
       "\n",
       "                                           rationale  \\\n",
       "0  To calculate the equivalent of miles in a kilo...   \n",
       "1  Let the length of the ship be x metres and its...   \n",
       "2  The question says, length of shorter piece is ...   \n",
       "3  For a point to satisfy the given equation for ...   \n",
       "4  Additional passengers (i.e., an integer, let's...   \n",
       "\n",
       "                                                  qn  clusters  \n",
       "0  three birds are flying at a fast rate of  kilo...         2  \n",
       "1  a ship is leaving a port. it takes  seconds to...         3  \n",
       "2  a rectangular piece of cloth  feet wide was cu...         3  \n",
       "3  in the xy-coordinate plane, which of the follo...         3  \n",
       "4  a travel company wants to charter a plane to t...         3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qbc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Named Entities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "def untokenize(tokens):\n",
    "    return(\"\".join([\" \"+i if not i.startswith(\"'\") and i not in string.punctuation else i for i in tokens]).strip())\n",
    "\n",
    "\n",
    "def extract_nonentities(tree):\n",
    "    tokens = [leaf[0] for leaf in tree if type(leaf) != nltk.Tree]\n",
    "    return(untokenize(tokens))\n",
    "\n",
    "def ne_removal(text_list):\n",
    "    token_list = [nltk.word_tokenize(text) for text in text_list]\n",
    "    tagged = nltk.pos_tag_sents(token_list)\n",
    "    chunked = nltk.ne_chunk_sents(tagged)\n",
    "    non_entities = []\n",
    "    for tree in chunked:\n",
    "        non_entities.append(extract_nonentities(tree))\n",
    "    return(non_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# removal of named entities\n",
    "qbc['qn'] = ne_removal(qbc['question'])\n",
    "#qbc['qn'] = (qbc['question'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre process text  - convert to lower case , remove numeric , special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "qbc.qn = qbc.qn.apply(lambda x: x.lower())\n",
    "qbc['qn'] = qbc['qn'].apply(lambda x: re.sub(r'\\%', 'percent', x))\n",
    "qbc['qn'] = qbc['qn'].apply(lambda x:re.sub(\"[^a-zA-Z]\",' ',x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the question into word list for vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>correct</th>\n",
       "      <th>options</th>\n",
       "      <th>question</th>\n",
       "      <th>rationale</th>\n",
       "      <th>qn</th>\n",
       "      <th>clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>['A)32400', 'B)6000', 'C)600', 'D)60000', 'E)10']</td>\n",
       "      <td>Three birds are flying at a fast rate of 900 k...</td>\n",
       "      <td>To calculate the equivalent of miles in a kilo...</td>\n",
       "      <td>three birds are flying at a fast rate of     k...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>['A)100 m', 'B)150 m', 'C)200 m', 'D)250 m', '...</td>\n",
       "      <td>A ship is leaving a port. It takes 240 seconds...</td>\n",
       "      <td>Let the length of the ship be x metres and its...</td>\n",
       "      <td>a ship is leaving a port  it takes     seconds...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>C</td>\n",
       "      <td>['A)6', 'B)18', 'C)24', 'D)36', 'E)48']</td>\n",
       "      <td>A rectangular piece of cloth 2 feet wide was c...</td>\n",
       "      <td>The question says, length of shorter piece is ...</td>\n",
       "      <td>a rectangular piece of cloth   feet wide was c...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>B</td>\n",
       "      <td>['A)(1,1)', 'B)(0,3)', 'C)(2,0)', 'D)(3,6)', '...</td>\n",
       "      <td>In the xy-coordinate plane, which of the follo...</td>\n",
       "      <td>For a point to satisfy the given equation for ...</td>\n",
       "      <td>in the xy coordinate plane  which of the follo...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>C</td>\n",
       "      <td>['A)7', 'B)9', 'C)13', 'D)27', 'E)45']</td>\n",
       "      <td>A travel company wants to charter a plane to t...</td>\n",
       "      <td>Additional passengers (i.e., an integer, let's...</td>\n",
       "      <td>a travel company wants to charter a plane to t...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 correct                                            options  \\\n",
       "0           0       A  ['A)32400', 'B)6000', 'C)600', 'D)60000', 'E)10']   \n",
       "1           1       D  ['A)100 m', 'B)150 m', 'C)200 m', 'D)250 m', '...   \n",
       "2           2       C            ['A)6', 'B)18', 'C)24', 'D)36', 'E)48']   \n",
       "3           3       B  ['A)(1,1)', 'B)(0,3)', 'C)(2,0)', 'D)(3,6)', '...   \n",
       "4           4       C             ['A)7', 'B)9', 'C)13', 'D)27', 'E)45']   \n",
       "\n",
       "                                            question  \\\n",
       "0  Three birds are flying at a fast rate of 900 k...   \n",
       "1  A ship is leaving a port. It takes 240 seconds...   \n",
       "2  A rectangular piece of cloth 2 feet wide was c...   \n",
       "3  In the xy-coordinate plane, which of the follo...   \n",
       "4  A travel company wants to charter a plane to t...   \n",
       "\n",
       "                                           rationale  \\\n",
       "0  To calculate the equivalent of miles in a kilo...   \n",
       "1  Let the length of the ship be x metres and its...   \n",
       "2  The question says, length of shorter piece is ...   \n",
       "3  For a point to satisfy the given equation for ...   \n",
       "4  Additional passengers (i.e., an integer, let's...   \n",
       "\n",
       "                                                  qn  clusters  \n",
       "0  three birds are flying at a fast rate of     k...         2  \n",
       "1  a ship is leaving a port  it takes     seconds...         3  \n",
       "2  a rectangular piece of cloth   feet wide was c...         3  \n",
       "3  in the xy coordinate plane  which of the follo...         3  \n",
       "4  a travel company wants to charter a plane to t...         3  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#qbc['qn']=qbc['qn'].apply(lambda x: x.split())\n",
    "qbc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize all the word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1573\n"
     ]
    }
   ],
   "source": [
    "AllText = qbc['qn'].values\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# prepare tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(AllText)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "print(vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 1000\n",
    "MAX_NB_WORDS = 20000\n",
    "EMBEDDING_DIM = 300\n",
    "VALIDATION_SPLIT = 0.3\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Merge, Dropout,Concatenate\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1572 unique tokens.\n",
      "Shape of data tensor: (254, 1000)\n",
      "Shape of label tensor: (254, 5)\n"
     ]
    }
   ],
   "source": [
    "texts =  qbc['qn'].values\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "\n",
    "labels=to_categorical(qbc['clusters'])\n",
    "#labels = to_categorical(labelenc.transform(qbc[\"Topic\"].values))\n",
    "\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "nb_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
    "\n",
    "x_train = data[:-nb_validation_samples]\n",
    "y_train = labels[:-nb_validation_samples]\n",
    "x_val = data[-nb_validation_samples:]\n",
    "y_val = labels[-nb_validation_samples:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the GloVe Word embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors from GloVe.\n"
     ]
    }
   ],
   "source": [
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "f = open('./glove.6B/glove.6B.300d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors from GloVe.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a word embeddings for the question vocabulary using the GloVe embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can't find Glove word vector for :thepercent\n",
      "Can't find Glove word vector for :prosthodontist\n",
      "Can't find Glove word vector for :yuvaraj\n",
      "Can't find Glove word vector for :playerwho\n",
      "Can't find Glove word vector for :whatpercent\n",
      "Can't find Glove word vector for :huhulians\n",
      "Can't find Glove word vector for :dbef\n",
      "Can't find Glove word vector for :koolaid\n",
      "Can't find Glove word vector for :irder\n"
     ]
    }
   ],
   "source": [
    "# create a weight matrix for words in training docs\n",
    "vocab = []\n",
    "embedding_matrix = np.zeros((vocab_size, 300))\n",
    "err_count = 0\n",
    "for word, i in t.word_index.items():\n",
    "    vocab.append(word)\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else :\n",
    "        print(\"Can't find Glove word vector for :{}\".format(word))\n",
    "        err_count +=1\n",
    "vocab.append(\"-null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1573, 300)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model fitting - convolutional neural network\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, 1000, 300)         471900    \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 996, 128)          192128    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 199, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 195, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 39, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 35, 128)           82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 845,281\n",
      "Trainable params: 845,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 178 samples, validate on 76 samples\n",
      "Epoch 1/15\n",
      "178/178 [==============================] - 8s 42ms/step - loss: 1.6679 - acc: 0.3034 - val_loss: 1.4375 - val_acc: 0.4737\n",
      "Epoch 2/15\n",
      "178/178 [==============================] - 7s 40ms/step - loss: 1.5210 - acc: 0.3596 - val_loss: 1.4647 - val_acc: 0.4737\n",
      "Epoch 3/15\n",
      "178/178 [==============================] - 7s 39ms/step - loss: 1.3846 - acc: 0.4607 - val_loss: 1.3836 - val_acc: 0.4737\n",
      "Epoch 4/15\n",
      "178/178 [==============================] - 7s 40ms/step - loss: 1.1006 - acc: 0.5899 - val_loss: 1.2993 - val_acc: 0.5132\n",
      "Epoch 5/15\n",
      "178/178 [==============================] - 7s 40ms/step - loss: 0.6503 - acc: 0.7921 - val_loss: 1.3515 - val_acc: 0.4868\n",
      "Epoch 6/15\n",
      "178/178 [==============================] - 7s 40ms/step - loss: 0.3099 - acc: 0.9326 - val_loss: 1.0581 - val_acc: 0.6184\n",
      "Epoch 7/15\n",
      "178/178 [==============================] - 7s 40ms/step - loss: 0.0776 - acc: 0.9888 - val_loss: 2.8683 - val_acc: 0.5263\n",
      "Epoch 8/15\n",
      "178/178 [==============================] - 7s 41ms/step - loss: 0.1242 - acc: 0.9775 - val_loss: 1.1791 - val_acc: 0.6447\n",
      "Epoch 9/15\n",
      "178/178 [==============================] - 7s 41ms/step - loss: 0.0093 - acc: 1.0000 - val_loss: 1.2376 - val_acc: 0.6447\n",
      "Epoch 10/15\n",
      "178/178 [==============================] - 7s 41ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 1.6824 - val_acc: 0.5921\n",
      "Epoch 11/15\n",
      "178/178 [==============================] - 8s 42ms/step - loss: 0.3754 - acc: 0.9157 - val_loss: 1.1346 - val_acc: 0.6842\n",
      "Epoch 12/15\n",
      "178/178 [==============================] - 7s 42ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 1.2760 - val_acc: 0.6579\n",
      "Epoch 13/15\n",
      "178/178 [==============================] - 7s 42ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 1.3093 - val_acc: 0.6579\n",
      "Epoch 14/15\n",
      "178/178 [==============================] - 7s 41ms/step - loss: 5.0276e-04 - acc: 1.0000 - val_loss: 1.5823 - val_acc: 0.6579\n",
      "Epoch 15/15\n",
      "178/178 [==============================] - 7s 41ms/step - loss: 1.7259e-04 - acc: 1.0000 - val_loss: 1.5459 - val_acc: 0.6447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a48eaaf98>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=True)\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "l_cov1= Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "l_pool1 = MaxPooling1D(5)(l_cov1)\n",
    "l_cov2 = Conv1D(128, 5, activation='relu')(l_pool1)\n",
    "l_pool2 = MaxPooling1D(5)(l_cov2)\n",
    "\n",
    "l_cov3 = Conv1D(128, 5, activation='relu')(l_pool2)\n",
    "l_pool3 = MaxPooling1D(35)(l_cov3)  # global max pooling\n",
    "l_flat = Flatten()(l_pool3)\n",
    "\n",
    "l_dense = Dense(128, activation='relu')(l_flat)\n",
    "preds = Dense(5, activation='softmax')(l_dense)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "\n",
    "print(\"model fitting - convolutional neural network\")\n",
    "model.summary()\n",
    "#model.fit(x_train, y_train, validation_data=(x_val, y_val),nb_epoch=10, batch_size=128)\n",
    "model.fit(x_train, y_train,validation_data=(x_val, y_val),epochs=15, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 64.47%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_val, y_val, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# applying a more complex convolutional approach\n",
    "convs = []\n",
    "filter_sizes = [3,4,5]\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "for fsz in filter_sizes:\n",
    "    l_conv = Conv1D(filters=128,kernel_size=fsz,activation='relu')(embedded_sequences)\n",
    "    l_pool = MaxPooling1D(5)(l_conv)\n",
    "    convs.append(l_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#l_merge = Merge(mode='concat', concat_axis=1)(convs)\n",
    "l_merge = Concatenate(axis=1)(convs)\n",
    "l_cov1= Conv1D(128, 5, activation='relu')(l_merge)\n",
    "l_pool1 = MaxPooling1D(5)(l_cov1)\n",
    "l_cov2 = Conv1D(128, 5, activation='relu')(l_pool1)\n",
    "l_pool2 = MaxPooling1D(30)(l_cov2)\n",
    "l_flat = Flatten()(l_pool2)\n",
    "l_dense = Dense(128, activation='relu')(l_flat)\n",
    "preds = Dense(5, activation='softmax')(l_dense)\n",
    "\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - complex CNN\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 1000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 1000, 300)    471900      input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 998, 128)     115328      embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 997, 128)     153728      embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 996, 128)     192128      embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling1D) (None, 199, 128)     0           conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling1D) (None, 199, 128)     0           conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling1D) (None, 199, 128)     0           conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 597, 128)     0           max_pooling1d_22[0][0]           \n",
      "                                                                 max_pooling1d_23[0][0]           \n",
      "                                                                 max_pooling1d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 593, 128)     82048       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling1D) (None, 118, 128)     0           conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 114, 128)     82048       max_pooling1d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling1D) (None, 3, 128)       0           conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 384)          0           max_pooling1d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 128)          49280       flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 5)            645         dense_15[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,147,105\n",
      "Trainable params: 1,147,105\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 178 samples, validate on 76 samples\n",
      "Epoch 1/15\n",
      "178/178 [==============================] - 20s 112ms/step - loss: 1.5598 - acc: 0.3539 - val_loss: 1.4441 - val_acc: 0.4737\n",
      "Epoch 2/15\n",
      "178/178 [==============================] - 18s 104ms/step - loss: 1.4890 - acc: 0.3483 - val_loss: 1.4803 - val_acc: 0.1842\n",
      "Epoch 3/15\n",
      "178/178 [==============================] - 19s 107ms/step - loss: 1.2668 - acc: 0.4775 - val_loss: 1.1836 - val_acc: 0.5658\n",
      "Epoch 4/15\n",
      "178/178 [==============================] - 20s 112ms/step - loss: 0.8188 - acc: 0.7022 - val_loss: 1.0077 - val_acc: 0.6316\n",
      "Epoch 5/15\n",
      "178/178 [==============================] - 21s 116ms/step - loss: 0.4266 - acc: 0.8371 - val_loss: 1.1097 - val_acc: 0.6053\n",
      "Epoch 6/15\n",
      "178/178 [==============================] - 20s 112ms/step - loss: 0.0766 - acc: 1.0000 - val_loss: 0.9800 - val_acc: 0.6842\n",
      "Epoch 7/15\n",
      "178/178 [==============================] - 20s 112ms/step - loss: 0.0735 - acc: 0.9888 - val_loss: 1.1758 - val_acc: 0.6316\n",
      "Epoch 8/15\n",
      "178/178 [==============================] - 19s 109ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 1.0261 - val_acc: 0.7105\n",
      "Epoch 9/15\n",
      "178/178 [==============================] - 19s 108ms/step - loss: 9.0489e-04 - acc: 1.0000 - val_loss: 1.3739 - val_acc: 0.6447\n",
      "Epoch 10/15\n",
      "178/178 [==============================] - 19s 106ms/step - loss: 2.9320e-04 - acc: 1.0000 - val_loss: 1.2549 - val_acc: 0.6579\n",
      "Epoch 11/15\n",
      "178/178 [==============================] - 19s 107ms/step - loss: 9.6859e-05 - acc: 1.0000 - val_loss: 1.6278 - val_acc: 0.6579\n",
      "Epoch 12/15\n",
      "178/178 [==============================] - 19s 105ms/step - loss: 4.2745e-05 - acc: 1.0000 - val_loss: 1.4744 - val_acc: 0.6579\n",
      "Epoch 13/15\n",
      "178/178 [==============================] - 18s 104ms/step - loss: 1.0349e-05 - acc: 1.0000 - val_loss: 1.6154 - val_acc: 0.6579\n",
      "Epoch 14/15\n",
      "178/178 [==============================] - 19s 105ms/step - loss: 3.7678e-06 - acc: 1.0000 - val_loss: 1.6662 - val_acc: 0.6579\n",
      "Epoch 15/15\n",
      "178/178 [==============================] - 18s 101ms/step - loss: 1.4087e-06 - acc: 1.0000 - val_loss: 1.7807 - val_acc: 0.6579\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a5636d9b0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Model - complex CNN\")\n",
    "model.summary()\n",
    "model.fit(x_train, y_train,validation_data=(x_val, y_val), epochs=15, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 65.79%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_val, y_val, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
